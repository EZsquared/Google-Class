{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "41c83497f39058fd582d274fa71e4d219ef214013fa6249d36393495a4462fd8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "import fileupload\n",
    "import io\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "FileUploadWidget(label='Browse', _dom_classes=('widget_item', 'btn-group'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "266fc2e9b22c4f8d8a853837d4a639a2"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# This is the uploader widget\n",
    "\n",
    "def _upload():\n",
    "\n",
    "    _upload_widget = fileupload.FileUploadWidget()\n",
    "\n",
    "    def _cb(change):\n",
    "        global file_contents\n",
    "        decoded = io.StringIO(change['owner'].data.decode('utf-8'))\n",
    "        filename = change['owner'].filename\n",
    "        print('Uploaded `{}` ({:.2f} kB)'.format(\n",
    "            filename, len(decoded.read()) / 2 **10))\n",
    "        file_contents = decoded.getvalue()\n",
    "\n",
    "    _upload_widget.observe(_cb, names='data')\n",
    "    display(_upload_widget)\n",
    "\n",
    "_upload()\n",
    "# The uploader widget saved the contents of your uploaded file into a string object named file_contents that your word cloud script can process. This was a lot of preliminary work, but you are now ready to begin your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on class WordCloud in module wordcloud.wordcloud:\n\nclass WordCloud(builtins.object)\n |  WordCloud(font_path=None, width=400, height=200, margin=2, ranks_only=None, prefer_horizontal=0.9, mask=None, scale=1, color_func=None, max_words=200, min_font_size=4, stopwords=None, random_state=None, background_color='black', max_font_size=None, font_step=1, mode='RGB', relative_scaling='auto', regexp=None, collocations=True, colormap=None, normalize_plurals=True, contour_width=0, contour_color='black', repeat=False, include_numbers=False, min_word_length=0, collocation_threshold=30)\n |  \n |  Word cloud object for generating and drawing.\n |  \n |  Parameters\n |  ----------\n |  font_path : string\n |      Font path to the font that will be used (OTF or TTF).\n |      Defaults to DroidSansMono path on a Linux machine. If you are on\n |      another OS or don't have this font, you need to adjust this path.\n |  \n |  width : int (default=400)\n |      Width of the canvas.\n |  \n |  height : int (default=200)\n |      Height of the canvas.\n |  \n |  prefer_horizontal : float (default=0.90)\n |      The ratio of times to try horizontal fitting as opposed to vertical.\n |      If prefer_horizontal < 1, the algorithm will try rotating the word\n |      if it doesn't fit. (There is currently no built-in way to get only\n |      vertical words.)\n |  \n |  mask : nd-array or None (default=None)\n |      If not None, gives a binary mask on where to draw words. If mask is not\n |      None, width and height will be ignored and the shape of mask will be\n |      used instead. All white (#FF or #FFFFFF) entries will be considerd\n |      \"masked out\" while other entries will be free to draw on. [This\n |      changed in the most recent version!]\n |  \n |  contour_width: float (default=0)\n |      If mask is not None and contour_width > 0, draw the mask contour.\n |  \n |  contour_color: color value (default=\"black\")\n |      Mask contour color.\n |  \n |  scale : float (default=1)\n |      Scaling between computation and drawing. For large word-cloud images,\n |      using scale instead of larger canvas size is significantly faster, but\n |      might lead to a coarser fit for the words.\n |  \n |  min_font_size : int (default=4)\n |      Smallest font size to use. Will stop when there is no more room in this\n |      size.\n |  \n |  font_step : int (default=1)\n |      Step size for the font. font_step > 1 might speed up computation but\n |      give a worse fit.\n |  \n |  max_words : number (default=200)\n |      The maximum number of words.\n |  \n |  stopwords : set of strings or None\n |      The words that will be eliminated. If None, the build-in STOPWORDS\n |      list will be used. Ignored if using generate_from_frequencies.\n |  \n |  background_color : color value (default=\"black\")\n |      Background color for the word cloud image.\n |  \n |  max_font_size : int or None (default=None)\n |      Maximum font size for the largest word. If None, height of the image is\n |      used.\n |  \n |  mode : string (default=\"RGB\")\n |      Transparent background will be generated when mode is \"RGBA\" and\n |      background_color is None.\n |  \n |  relative_scaling : float (default='auto')\n |      Importance of relative word frequencies for font-size.  With\n |      relative_scaling=0, only word-ranks are considered.  With\n |      relative_scaling=1, a word that is twice as frequent will have twice\n |      the size.  If you want to consider the word frequencies and not only\n |      their rank, relative_scaling around .5 often looks good.\n |      If 'auto' it will be set to 0.5 unless repeat is true, in which\n |      case it will be set to 0.\n |  \n |      .. versionchanged: 2.0\n |          Default is now 'auto'.\n |  \n |  color_func : callable, default=None\n |      Callable with parameters word, font_size, position, orientation,\n |      font_path, random_state that returns a PIL color for each word.\n |      Overwrites \"colormap\".\n |      See colormap for specifying a matplotlib colormap instead.\n |      To create a word cloud with a single color, use\n |      ``color_func=lambda *args, **kwargs: \"white\"``.\n |      The single color can also be specified using RGB code. For example\n |      ``color_func=lambda *args, **kwargs: (255,0,0)`` sets color to red.\n |  \n |  regexp : string or None (optional)\n |      Regular expression to split the input text into tokens in process_text.\n |      If None is specified, ``r\"\\w[\\w']+\"`` is used. Ignored if using\n |      generate_from_frequencies.\n |  \n |  collocations : bool, default=True\n |      Whether to include collocations (bigrams) of two words. Ignored if using\n |      generate_from_frequencies.\n |  \n |  \n |      .. versionadded: 2.0\n |  \n |  colormap : string or matplotlib colormap, default=\"viridis\"\n |      Matplotlib colormap to randomly draw colors from for each word.\n |      Ignored if \"color_func\" is specified.\n |  \n |      .. versionadded: 2.0\n |  \n |  normalize_plurals : bool, default=True\n |      Whether to remove trailing 's' from words. If True and a word\n |      appears with and without a trailing 's', the one with trailing 's'\n |      is removed and its counts are added to the version without\n |      trailing 's' -- unless the word ends with 'ss'. Ignored if using\n |      generate_from_frequencies.\n |  \n |  repeat : bool, default=False\n |      Whether to repeat words and phrases until max_words or min_font_size\n |      is reached.\n |  \n |  include_numbers : bool, default=False\n |      Whether to include numbers as phrases or not.\n |  \n |  min_word_length : int, default=0\n |      Minimum number of letters a word must have to be included.\n |  \n |  collocation_threshold: int, default=30\n |      Bigrams must have a Dunning likelihood collocation score greater than this\n |      parameter to be counted as bigrams. Default of 30 is arbitrary.\n |  \n |      See Manning, C.D., Manning, C.D. and Sch√ºtze, H., 1999. Foundations of\n |      Statistical Natural Language Processing. MIT press, p. 162\n |      https://nlp.stanford.edu/fsnlp/promo/colloc.pdf#page=22\n |  \n |  Attributes\n |  ----------\n |  ``words_`` : dict of string to float\n |      Word tokens with associated frequency.\n |  \n |      .. versionchanged: 2.0\n |          ``words_`` is now a dictionary\n |  \n |  ``layout_`` : list of tuples (string, int, (int, int), int, color))\n |      Encodes the fitted word cloud. Encodes for each word the string, font\n |      size, position, orientation and color.\n |  \n |  Notes\n |  -----\n |  Larger canvases with make the code significantly slower. If you need a\n |  large word cloud, try a lower canvas size, and set the scale parameter.\n |  \n |  The algorithm might give more weight to the ranking of the words\n |  than their actual frequencies, depending on the ``max_font_size`` and the\n |  scaling heuristic.\n |  \n |  Methods defined here:\n |  \n |  __array__(self)\n |      Convert to numpy array.\n |      \n |      Returns\n |      -------\n |      image : nd-array size (width, height, 3)\n |          Word cloud image as numpy matrix.\n |  \n |  __init__(self, font_path=None, width=400, height=200, margin=2, ranks_only=None, prefer_horizontal=0.9, mask=None, scale=1, color_func=None, max_words=200, min_font_size=4, stopwords=None, random_state=None, background_color='black', max_font_size=None, font_step=1, mode='RGB', relative_scaling='auto', regexp=None, collocations=True, colormap=None, normalize_plurals=True, contour_width=0, contour_color='black', repeat=False, include_numbers=False, min_word_length=0, collocation_threshold=30)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  fit_words(self, frequencies)\n |      Create a word_cloud from words and frequencies.\n |      \n |      Alias to generate_from_frequencies.\n |      \n |      Parameters\n |      ----------\n |      frequencies : dict from string to float\n |          A contains words and associated frequency.\n |      \n |      Returns\n |      -------\n |      self\n |  \n |  generate(self, text)\n |      Generate wordcloud from text.\n |      \n |      The input \"text\" is expected to be a natural text. If you pass a sorted\n |      list of words, words will appear in your output twice. To remove this\n |      duplication, set ``collocations=False``.\n |      \n |      Alias to generate_from_text.\n |      \n |      Calls process_text and generate_from_frequencies.\n |      \n |      Returns\n |      -------\n |      self\n |  \n |  generate_from_frequencies(self, frequencies, max_font_size=None)\n |      Create a word_cloud from words and frequencies.\n |      \n |      Parameters\n |      ----------\n |      frequencies : dict from string to float\n |          A contains words and associated frequency.\n |      \n |      max_font_size : int\n |          Use this font-size instead of self.max_font_size\n |      \n |      Returns\n |      -------\n |      self\n |  \n |  generate_from_text(self, text)\n |      Generate wordcloud from text.\n |      \n |      The input \"text\" is expected to be a natural text. If you pass a sorted\n |      list of words, words will appear in your output twice. To remove this\n |      duplication, set ``collocations=False``.\n |      \n |      Calls process_text and generate_from_frequencies.\n |      \n |      ..versionchanged:: 1.2.2\n |          Argument of generate_from_frequencies() is not return of\n |          process_text() any more.\n |      \n |      Returns\n |      -------\n |      self\n |  \n |  process_text(self, text)\n |      Splits a long text into words, eliminates the stopwords.\n |      \n |      Parameters\n |      ----------\n |      text : string\n |          The text to be processed.\n |      \n |      Returns\n |      -------\n |      words : dict (string, int)\n |          Word tokens with associated frequency.\n |      \n |      ..versionchanged:: 1.2.2\n |          Changed return type from list of tuples to dict.\n |      \n |      Notes\n |      -----\n |      There are better ways to do word tokenization, but I don't want to\n |      include all those things.\n |  \n |  recolor(self, random_state=None, color_func=None, colormap=None)\n |      Recolor existing layout.\n |      \n |      Applying a new coloring is much faster than generating the whole\n |      wordcloud.\n |      \n |      Parameters\n |      ----------\n |      random_state : RandomState, int, or None, default=None\n |          If not None, a fixed random state is used. If an int is given, this\n |          is used as seed for a random.Random state.\n |      \n |      color_func : function or None, default=None\n |          Function to generate new color from word count, font size, position\n |          and orientation.  If None, self.color_func is used.\n |      \n |      colormap : string or matplotlib colormap, default=None\n |          Use this colormap to generate new colors. Ignored if color_func\n |          is specified. If None, self.color_func (or self.color_map) is used.\n |      \n |      Returns\n |      -------\n |      self\n |  \n |  to_array(self)\n |      Convert to numpy array.\n |      \n |      Returns\n |      -------\n |      image : nd-array size (width, height, 3)\n |          Word cloud image as numpy matrix.\n |  \n |  to_file(self, filename)\n |      Export to image file.\n |      \n |      Parameters\n |      ----------\n |      filename : string\n |          Location to write to.\n |      \n |      Returns\n |      -------\n |      self\n |  \n |  to_html(self)\n |  \n |  to_image(self)\n |  \n |  to_svg(self, embed_font=False, optimize_embedded_font=True, embed_image=False)\n |      Export to SVG.\n |      \n |      Font is assumed to be available to the SVG reader. Otherwise, text\n |      coordinates may produce artifacts when rendered with replacement font.\n |      It is also possible to include a subset of the original font in WOFF\n |      format using ``embed_font`` (requires `fontTools`).\n |      \n |      Note that some renderers do not handle glyphs the same way, and may\n |      differ from ``to_image`` result. In particular, Complex Text Layout may\n |      not be supported. In this typesetting, the shape or positioning of a\n |      grapheme depends on its relation to other graphemes.\n |      \n |      Pillow, since version 4.2.0, supports CTL using ``libraqm``. However,\n |      due to dependencies, this feature is not always enabled. Hence, the\n |      same rendering differences may appear in ``to_image``. As this\n |      rasterized output is used to compute the layout, this also affects the\n |      layout generation. Use ``PIL.features.check`` to test availability of\n |      ``raqm``.\n |      \n |      Consistant rendering is therefore expected if both Pillow and the SVG\n |      renderer have the same support of CTL.\n |      \n |      Contour drawing is not supported.\n |      \n |      Parameters\n |      ----------\n |      embed_font : bool, default=False\n |          Whether to include font inside resulting SVG file.\n |      \n |      optimize_embedded_font : bool, default=True\n |          Whether to be aggressive when embedding a font, to reduce size. In\n |          particular, hinting tables are dropped, which may introduce slight\n |          changes to character shapes (w.r.t. `to_image` baseline).\n |      \n |      embed_image : bool, default=False\n |          Whether to include rasterized image inside resulting SVG file.\n |          Useful for debugging.\n |      \n |      Returns\n |      -------\n |      content : string\n |          Word cloud image as SVG string\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n"
     ]
    }
   ],
   "source": [
    "help(wordcloud.WordCloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequencies(file_contents):\n",
    "    # Here is a list of punctuations and uninteresting words you can use to process your text\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    uninteresting_words = [\"the\", \"a\", \"to\", \"if\", \"is\", \"it\", \"of\", \"and\", \"or\", \"an\", \"as\", \"i\", \"me\", \"my\", \\\n",
    "    \"we\", \"our\", \"ours\", \"you\", \"your\", \"yours\", \"he\", \"she\", \"him\", \"his\", \"her\", \"hers\", \"its\", \"they\", \"them\", \\\n",
    "    \"their\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"am\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \\\n",
    "    \"have\", \"has\", \"had\", \"do\", \"does\", \"did\", \"but\", \"at\", \"by\", \"with\", \"from\", \"here\", \"when\", \"where\", \"how\", \\\n",
    "    \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"some\", \"such\", \"no\", \"nor\", \"too\", \"very\", \"can\", \"will\", \"just\"]\n",
    "    \n",
    "    # LEARNER CODE START HERE\n",
    "    cloud_dict = {}\n",
    "    words = file_contents.split()\n",
    "    cleaned_words = [word.lower().strip(punctuations) for word in words]\n",
    "    cloud_words = [word for word in cleaned_words if word not in uninteresting_words]\n",
    "    \n",
    "    for word in cloud_words:\n",
    "        if word not in cloud_dict.keys():\n",
    "            cloud_dict[word] = 0\n",
    "            \n",
    "        cloud_dict[word] += 1\n",
    "        \n",
    "    #wordcloud\n",
    "    cloud = wordcloud.WordCloud()\n",
    "    cloud.generate_from_frequencies(cloud_dict)\n",
    "    return cloud.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myimage = calculate_frequencies(file_contents)\n",
    "plt.imshow(myimage, interpolation = 'nearest')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ]
}